ğŸ¯ QueryMind â€” AI-Powered RAG Chat App

QueryMind is a cross-platform AI chatbot built with **Flutter** and powered by a **FastAPI backend** that uses Google's **Gemini API**. It leverages **Retrieval-Augmented Generation (RAG)** to search, retrieve, and respond with accurate, context-rich answers from the web or document corpus.

ğŸ§° Tech Stack

ğŸ”™ Backend  
- FastAPI (Python)
- Gemini API (LLM)
- WebSocket API for streaming responses
- Cosine Similarity & Vector Search (custom logic)
- Async I/O with `httpx`, `websockets`, etc.

ğŸ“± Frontend  
- Flutter (Cross-platform: Android, iOS, Web, Desktop)
- Riverpod (State Management)
- Flutter Markdown for rich text rendering
- WebSocket client for live streaming responses
- Skeletonizer for UI loading states

ğŸ”¥ Key Features

ğŸ§  Retrieval-Augmented Generation (RAG)  
ğŸ” Real-time search over online sources  
ğŸ§® Cosine similarity-based document retrieval  
ğŸ’¬ Gemini LLM API integration with prompt engineering  
ğŸ“¡ WebSocket-based live streaming responses  
ğŸ“ Markdown support for AI replies  
ğŸ“± Optimized and responsive UI (desktop & mobile)  
ğŸ­ Loading skeletons for smoother UX

ğŸš€ Getting Started

ğŸ“¦ Prerequisites
- Python 3.9+
- Flutter SDK
- Dart SDK â‰¥ 3.7.0
- Gemini API Key (from Google AI Studio)

ğŸ Backend Setup

```bash
# Clone the repo
git clone https://github.com/Desmopk/querymind.git
cd querymind/backend

# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up your Gemini API Key in `.env`
cp .env.example .env

# Run the FastAPI server
uvicorn main:app --reload
```
ğŸ“± Frontend Setup

```bash
cd ../flutter_client

# Install Flutter packages
flutter pub get

# Run on emulator or real device
flutter run
```
ğŸ§  RAG Architecture Overview

User Prompt â†’
- FastAPI receives input
- Search external content sources
- Compute cosine similarity to rank sources
- Send top documents and prompt to Gemini LLM
- Stream response via WebSocket
- Flutter displays live chat with Markdown rendering

ğŸ›¡ï¸ Token & API Security

- Gemini API key stored in .env (never hardcoded)
- API routes are scoped and minimal
- No user auth required for demo, but JWT can be added

ğŸ“¦ Deployment

- Backend: Deployable via Docker, Uvicorn/Gunicorn
- Frontend: Flutter web or native builds
- Future enhancements: Vector DB integration, Authentication, Chat history
ğŸ“‚ Repository Structure
```bash
querymind/
â”œâ”€â”€ backend/          # FastAPI backend
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ services/     # Gemini API, RAG logic
â”‚   â”œâ”€â”€ utils/        # Text processing, similarity
â”‚   â””â”€â”€ .env          # API keys & config
â””â”€â”€ flutter_client/   # Flutter frontend
    â”œâ”€â”€ lib/
    â”œâ”€â”€ assets/
    â””â”€â”€ pubspec.yaml
```

